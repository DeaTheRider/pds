{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (*) Написать свою реализацию метода главных компонент с помощью сингулярного разложения с использованием функции [numpy.linalg.svd()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузим игрушечный датасет из sklearn\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "U,D,V = np.linalg.svd(X,full_matrices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(9, 6) + 1j*np.random.randn(9, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 6)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "U,D,V = np.linalg.svd(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(U * D, V).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля дисперсии, описвыаемая каждой из компонент \n",
      "[80.59340691495326, 14.916876798004958, 2.9067159767294926, 1.5830003103122972]\n",
      "Кумулятивная доля дисперсии по компонентам \n",
      "[ 80.59340691  95.51028371  98.41699969 100.        ]\n"
     ]
    }
   ],
   "source": [
    "eig_sum = sum(D)\n",
    "var_exp = [(i / eig_sum) * 100 for i in sorted(D, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print(f'Доля дисперсии, описвыаемая каждой из компонент \\n{var_exp}')\n",
    "\n",
    "# а теперя оценим кумулятивную (то есть накапливаемую) дисперсию при учитывании каждой из компонент\n",
    "print(f'Кумулятивная доля дисперсии по компонентам \\n{cum_var_exp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.75110816,  0.2841749 ,  0.50215472,  0.32081425],\n",
       "       [-0.38008617,  0.5467445 , -0.67524332, -0.31725607],\n",
       "       [-0.51300886, -0.70866455, -0.05916621, -0.48074507],\n",
       "       [-0.16790754, -0.34367081, -0.53701625,  0.75187165]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Матрица весов W:\n",
      " [[-0.75110816 -0.38008617]\n",
      " [ 0.2841749   0.5467445 ]\n",
      " [ 0.50215472 -0.67524332]\n",
      " [ 0.32081425 -0.31725607]]\n"
     ]
    }
   ],
   "source": [
    "W = np.hstack((V.T[0].reshape(4,1), V.T[1].reshape(4,1)))\n",
    "\n",
    "print(f'Матрица весов W:\\n', W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = X.dot(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (*) Обучить любую модель классификации на датасете IRIS до применения PCA и после него. Сравнить качество классификации по отложенной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import datasets\n",
    "\n",
    "import numpy as np\n",
    "y = iris.target\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = model_selection.train_test_split(Z, y, test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_predict(X, trees_list, coef_list, eta):\n",
    "    # Реализуемый алгоритм градиентного бустинга будет инициализироваться нулевыми значениями,\n",
    "    # поэтому все деревья из списка trees_list уже являются дополнительными и при предсказании прибавляются с шагом eta\n",
    "    return np.array([sum([eta* coef * alg.predict([x])[0] for alg, coef in zip(trees_list, coef_list)]) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_real, prediction):\n",
    "    return (sum((y_real - prediction)**2)) / len(y_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias(y, z):\n",
    "    return (y - z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_fit(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta):\n",
    "    \n",
    "    # Деревья будем записывать в список\n",
    "    trees = []\n",
    "    \n",
    "    # Будем записывать ошибки на обучающей и тестовой выборке на каждой итерации в список\n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "    \n",
    "    for i in range(n_trees):\n",
    "        tree = DecisionTreeRegressor(max_depth=max_depth, random_state=42)\n",
    "\n",
    "        # инициализируем бустинг начальным алгоритмом, возвращающим ноль, \n",
    "        # поэтому первый алгоритм просто обучаем на выборке и добавляем в список\n",
    "        if len(trees) == 0:\n",
    "            # обучаем первое дерево на обучающей выборке\n",
    "            tree.fit(X_train, y_train)\n",
    "            \n",
    "            train_errors.append(mean_squared_error(y_train, gb_predict(X_train, trees, coefs, eta)))\n",
    "            test_errors.append(mean_squared_error(y_test, gb_predict(X_test, trees, coefs, eta)))\n",
    "        else:\n",
    "            # Получим ответы на текущей композиции\n",
    "            target = gb_predict(X_train, trees, coefs, eta)\n",
    "            \n",
    "            # алгоритмы начиная со второго обучаем на сдвиг\n",
    "            tree.fit(X_train, bias(y_train, target))\n",
    "            \n",
    "            train_errors.append(mean_squared_error(y_train, gb_predict(X_train, trees, coefs, eta)))\n",
    "            test_errors.append(mean_squared_error(y_test, gb_predict(X_test, trees, coefs, eta)))\n",
    "\n",
    "        trees.append(tree)\n",
    "        \n",
    "    return trees, train_errors, test_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Число деревьев в ансамбле\n",
    "n_trees = 3\n",
    "\n",
    "# для простоты примем коэффициенты равными 1\n",
    "coefs = [1] * n_trees\n",
    "\n",
    "# Максимальная глубина деревьев\n",
    "max_depth = 1\n",
    "\n",
    "# Шаг\n",
    "eta = 1\n",
    "\n",
    "trees, train_errors, test_errors = gb_fit(n_trees, max_depth, X_train, X_test, y_train, y_test, coefs, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_alg(X_train, X_test, y_train, y_test, trees, coefs, eta):\n",
    "    train_prediction = gb_predict(X_train, trees, coefs, eta)\n",
    "\n",
    "    print(f'Ошибка алгоритма из {n_trees} деревьев глубиной {max_depth} \\\n",
    "    с шагом {eta} на тренировочной выборке: {mean_squared_error(y_train, train_prediction)}')\n",
    "\n",
    "    test_prediction = gb_predict(X_test, trees, coefs, eta)\n",
    "\n",
    "    print(f'Ошибка алгоритма из {n_trees} деревьев глубиной {max_depth} \\\n",
    "    с шагом {eta} на тестовой выборке: {mean_squared_error(y_test, test_prediction)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка алгоритма из 3 деревьев глубиной 1     с шагом 1 на тренировочной выборке: 0.05297506114803795\n",
      "Ошибка алгоритма из 3 деревьев глубиной 1     с шагом 1 на тестовой выборке: 0.015413382648690044\n"
     ]
    }
   ],
   "source": [
    "evaluate_alg(X_train, X_test, y_train, y_test, trees, coefs, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ошибка алгоритма из 3 деревьев глубиной 1     с шагом 1 на тренировочной выборке: 0.0568663007958561\n",
      "Ошибка алгоритма из 3 деревьев глубиной 1     с шагом 1 на тестовой выборке: 0.052880078499875596\n"
     ]
    }
   ],
   "source": [
    "# Число деревьев в ансамбле\n",
    "n_trees = 3\n",
    "\n",
    "# для простоты примем коэффициенты равными 1\n",
    "coefs = [1] * n_trees\n",
    "\n",
    "# Максимальная глубина деревьев\n",
    "max_depth = 1\n",
    "\n",
    "# Шаг\n",
    "eta = 1\n",
    "\n",
    "trees, train_errors, test_errors = gb_fit(n_trees, max_depth, X_train1, X_test1, y_train1, y_test1, coefs, eta)\n",
    "evaluate_alg(X_train1, X_test1, y_train1, y_test1, trees, coefs, eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С применением PCA на тестовой выборки результат лучше чем без него "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
